{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for data cleaning\n",
    "\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set the path to the directory containing the images\n",
    "data_dir = '/content/face/confident'\n",
    "\n",
    "# Create an instance of the MTCNN model\n",
    "detector = MTCNN()\n",
    "\n",
    "# Create a new directory to store the filtered images\n",
    "filtered_dir = os.path.join(data_dir, 'filtered_conf')\n",
    "os.makedirs(filtered_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each image in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Read the image file\n",
    "        img_path = os.path.join(data_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        # Detect faces in the image\n",
    "        faces = detector.detect_faces(img)\n",
    "        # Check if the image contains any faces\n",
    "        if len(faces) == 0:\n",
    "            # If there are no faces, move the image to the filtered directory\n",
    "            shutil.move(img_path, os.path.join(filtered_dir, filename))\n",
    "            print(f\"{filename} moved to filtered directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.applications import VGG19\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths for train, val and test sets\n",
    "train_data_dir = '/content/confident-unconfident/train'\n",
    "validation_data_dir = '/content/confident-unconfident/val'\n",
    "test_data_dir = '/content/confident-unconfident/test'\n",
    "\n",
    "# Define image dimensions and batch size\n",
    "img_height = 256\n",
    "img_width =256\n",
    "batch_size = 32\n",
    "num_classes=2\n",
    "\n",
    "# Load train, val and test sets\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3),padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3),padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "#Optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback])\n",
    "\n",
    "# to get detail analysis of epochs go to anaconda prompt cd to directory where logs are store and execute \n",
    "# following command tensorboard --logdir=. --bind_all\n",
    "#it will give you url for tensorboard\n",
    "  \n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Save the model\n",
    "model.save('/content/model.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 48,48\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  #my inference remove dropout layer because may be my model required more feature\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/content/confident-unconfident/train'\n",
    "validation_data_dir = '/content/confident-unconfident/val'\n",
    "test_data_dir = '/content/confident-unconfident/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('/content/modelvgg19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot evaluation matrix\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define test data directory and image dimensions\n",
    "test_data_dir = '/content/confident-unconfident/test'\n",
    "img_width, img_height = 256, 256  # replace with your image dimensions\n",
    "\n",
    "# Create an ImageDataGenerator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the test data from directory using flow_from_directory method\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('/content/Confident_level_prediction_final_9_march.h5')\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.round(y_pred).astype(int)\n",
    "\n",
    "# Get the true labels of the test data\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "#print(classification_report(y_true, y_pred_classes))\n",
    "#print(\"Confusion Matrix:\")\n",
    "#print(confusion_matrix(y_true, y_pred_classes))\n",
    "\n",
    "#heat map\n",
    "#heatmap\n",
    "# generate classification report and confusion matrix\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# create heatmap for the confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing of model\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('/content/Confident_level_prediction_final_9_march.h5')\n",
    "model.compile() \n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread(\"/content/240_F_288471634_PRcyq2VkvTVlhHBDUkiwBRh0TQSDiTiy.jpg\")\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()\n",
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "print(yhat)\n",
    "if yhat >= 0.55:\n",
    "    print(f'Predicted class is confident')\n",
    "elif(yhat<=0.35):\n",
    "    print(f'Predicted class is unconfident')\n",
    "else:\n",
    "    print(f'prediction class is neutral')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
